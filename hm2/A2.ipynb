{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b3a29",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"A2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb4cd0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68f2f0ed9883b594",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "## **Due: Oct 11th (Friday), 2024, 11:59pm (Pacific Time)**\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "Your Jupyter notebook assignment will often have 3 elements: written answers, code answers, and quiz answers. For written answers, you may insert images of your handwritten work in code cells, or write your answers in markdown and LaTeX. For quiz answers, your `record.txt` file will record your answer choices in the quiz modules for submission. Both your quiz answers and code answers will be autograded on Gradescope. This assignment does not have the quiz portion.\n",
    "\n",
    "For all elements, DO NOT MODIFY THE CELLS. Put your answers **only** in the answer cells given, and **do not delete cells**. If you fail to follow these instructions, you will lose points on your submission.\n",
    "\n",
    "Make sure to show the steps of your solution for every question to receive credit, not just the final answer. You may search information online but you will need to write code/find solutions to answer the questions yourself. You will submit your .ipynb file and record.txt to gradescope when you are finished.\n",
    "\n",
    "### **Late Policy:**\n",
    "\n",
    "5% reduction for the first day and 10% reduction afterwards for every extra day past due.\n",
    "\n",
    "### How to Include Your Math Written Answer?\n",
    "\n",
    "You could use markdowns' include image functionality (recommended) or $\\LaTeX$ in markdown to submit your written responses.\n",
    "\n",
    "#### Include Images (recommended)\n",
    "If you are still getting familiar with using LaTeX, handwrite the response on paper or the stylus. Take a picture or screenshot of your answer, and include that image in the Jupyter Notebook. Be sure to include that image in the `\\imgs` directory. Let's say you have your Q1 response saved as `imgs/Q1.png`; the markdown syntax to include that image is `![Q1](imgs/Q1.png)`.\n",
    "\n",
    "#### $\\LaTeX$\n",
    "[Here is a fantastic tutorial from CalTech about using $\\LaTeX$ in Jupyter Notebook.](http://chebe163.caltech.edu/2018w/handouts/intro_to_latex.html). You could also find various $\\LaTeX$ tutorials and cheat sheets online.\n",
    "\n",
    "## Important Notice\n",
    "\n",
    "You must check both submission output on the gradescope (`Assignment 2 - Notebook` and `Assignment 2 - Manual Grading`) correctly reflects your work and responses. If you notice inconsistencies between your notebook and the Manual Grading portion, you need to make a Piazza post, and we can help you with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a206c8",
   "metadata": {},
   "source": [
    "# Question 1: Conceptual Questions\n",
    "\n",
    "Multiple Choice Section\n",
    "\n",
    "Write your solution as a list of strings by replacing the \"...\" \n",
    "\n",
    "Ex.: `[\"A\", \"C\"]` if you think the answers are A and C). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf140878",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.1\n",
    "\n",
    "Is the following statement true or false? $f(x)$ is linear with respect to $x$, given $f(x) = w_0 + w_1x + w_2x^2$ where $x, w_0, w_1, w_2 \\in R$.\n",
    "\n",
    "A. True\\\n",
    "B. False\n",
    "\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe3cfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302b7ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"A1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd68c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.2\n",
    "\n",
    "\"One-hot encoding\" is a standard technique that turns categorical features into general real numbers. If we have a dataset $S$ containing $m$ data points where each data point has 1 categorical feature. Specifically, this categorical feature has $k$ possible categories. Thus, the shape of the one-hot encoding matrix that represents the dataset $S$ is:\n",
    "\n",
    "A. $k\\times k$\\\n",
    "B. $1\\times k$\\\n",
    "C. $m\\times k$\\\n",
    "D. $m\\times m$\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c3781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7d3c2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"A1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e8f63",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.3\n",
    "\n",
    "Assume we have a binary classification model:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(\\mathbf{x})&=\n",
    "\\begin{cases}\n",
    "+1, & w \\cdot x + b \\ge 0, \\\\\n",
    "-1, & w \\cdot x + b < 0. \n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the feature vector $x = (x_1, x_2) \\in R^2$, bias $b \\in R$, weight vector $w = (w_1, w_2) \\in R^2$. The decision boundary of the classification model is: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    " w \\cdot x + b = 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Part (a) \n",
    "\n",
    "If the predictions of the classifier f and its decision boundary $w \\cdot x + b = 0$ are shown in the figure below, which one below can be a possible solution of weight vector $w$ and bias $b$? \n",
    "\n",
    "![img1](imgs/1.png)\n",
    "\n",
    "A. $w = (+1, 0); b = -1$\n",
    "\n",
    "B. $w = (-1, 0); b = +1$\n",
    "\n",
    "C. $w = (+1, 0); b = +1$\n",
    "\n",
    "D. $w = (0, -1); b = -1$\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454158b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1_3a = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8a7e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"A1_3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5a1dd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part (b) \n",
    "\n",
    "If the predictions of the classifier f and its decision boundary $w \\cdot x + b = 0$ are shown in the figure below, which one below can be a possible solution of weight vector $w$ and bias $b$? \n",
    "\n",
    "![Img2](imgs/2.png)\n",
    "\n",
    "A. $w = (+1, 0); b = -1$\n",
    "\n",
    "B. $w = (-1, 0); b = +1$\n",
    "\n",
    "C. $w = (+1, 0); b = +1$\n",
    "\n",
    "D. $w = (0, -1); b = -1$\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df682b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1_3b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686fab90",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"A1_3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e155d9b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.4\n",
    "\n",
    "Choose the most significant difference between regression and classification:\n",
    "\n",
    "A. unsupervised learning vs. supervised learning\n",
    "\n",
    "B. prediction of continuous values vs. prediction of class labels\n",
    "\n",
    "C. features are not one-hot encoded vs features are one-hot encoded\n",
    "\n",
    "D. none of the above\n",
    "\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01eaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873a617",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"A1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8676f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 2 Decision Boundary\n",
    "\n",
    "### 2.1\n",
    "\n",
    "We are given a classifier that performs classification in $R^2$(the space of data points with 2 features ($x_1,x_2$)) with the following decision rule:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h(x_1,x_2)&=\n",
    "\\begin{cases}\n",
    " +1, & x_1+2x_2 -4 \\geq 0, \\\\\n",
    "-1, & \\text{otherwise}. \n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $h(\\mathbf{x})\\in \\{-1,+1\\}$ is the predicted label. Please solve the following problems. \n",
    "\n",
    "Draw the decision boundary of the given classifier and shade the region where the classifier predicts +1. Make sure you have marked the $x_1$ and $x_2$ axes and the intercepts on those axes.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0624dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the x1 and x2 of points on the decision boundary\n",
    "boundary_x1s = np.linspace(-2, 6, 20)\n",
    "# STEP 1, x2s are calculated from x1s\n",
    "boundary_x2s = ...\n",
    "\n",
    "# plot the boundary\n",
    "plt.plot(boundary_x1s, boundary_x2s)\n",
    "plt.xlim([-2.2, 2.2])\n",
    "plt.ylim([-2.2, 2.2])\n",
    "plt.annotate('x1', [2, 0.2], weight='bold')\n",
    "plt.annotate('x2', [0.2, 2], weight='bold')\n",
    "\n",
    "# generate some random data points\n",
    "np.random.seed(0)\n",
    "N_samples = 60\n",
    "sample_x1s = np.random.rand(N_samples) * 8 - 2 \n",
    "sample_x2s = np.random.rand(N_samples) * 6 - 2\n",
    "\n",
    "# predict the labels (1 or -1) of the samples, here the signed_distance is given by the equation x1+2*x2-4\n",
    "# STEP 2\n",
    "signed_distance = ...\n",
    "# STEP 3\n",
    "positive = signed_distance >= 0\n",
    "negative = signed_distance < 0\n",
    "\n",
    "# plot the samples\n",
    "plt.scatter(sample_x1s[positive], sample_x2s[positive], color=\"g\", marker=\"+\", label='positive')\n",
    "plt.scatter(sample_x1s[negative], sample_x2s[negative], color=\"r\", marker=\"_\", label='negative')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.set_xticks( [-4, -2, 0, 2, 4, 6])\n",
    "ax.set_yticks( [-2, -1, 1, 2, 3])\n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79adc0c5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2.2\n",
    "\n",
    "We are given a classifier that performs classification on $R^2$ (the space of data points with 2 features $(x_1, x_2)$) with the following decision rule:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h(x_1,x_2)&=\n",
    "\\begin{cases}\n",
    " +1, & w_1x_1+w_2x_2 + b \\geq 0, \\\\\n",
    "-1, & \\text{otherwise}. \n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here, the normal vector $w$ of the decision boundary is normalized, i.e.:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "||\\textbf{w}||_2=\\sqrt{w_1^2+w_2^2}=1.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "(1) Compute the parameters $w_1$, $w_2$ and $b$ for the decision boundary in the figure below. Please make sure the predictions from the obtained classifier are consistent with the figure.\n",
    "\n",
    "**Hint**: Please use the intercepts in the figure below to find the relation between $w_1$, $w_2$ and\n",
    "$b$. Then, substitute it into the normalization constraint to solve for parameters.\n",
    "\n",
    "\n",
    "(2) Use parameters from the above question to compute predictions for the following two data points: $A = (3, 2), B = (âˆ’1, 0)$.\n",
    "\n",
    "![Img3](imgs/3.png)\n",
    "\n",
    "_Points:_ 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0bb6fc",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea6217d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2.3\n",
    "\n",
    "We are given a classifier that performs classification on $\\mathbb{R}^3$ (the space of data points with 3 features $(x_1,x_2,x_3)$) with the following decision rule: \n",
    "\n",
    "\\begin{equation}\n",
    "h(x_1,x_2,x_3) = \\left\\{\n",
    "             \\begin{array}{ll}\n",
    "             1,  & \\text{if } w_1x_1 + w_2x_2 + w_3 x_3 + b \\ge 0\\\\\n",
    "             0,  & \\text{otherwise} . \n",
    "             \\end{array}  \n",
    "        \\right. \\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Here, the normal vector $\\mathbf{w}$ of the decision boundary is normalized, i.e.:\n",
    "\n",
    "\\begin{equation} \n",
    "||\\mathbf{w}||_2 = \\sqrt{w^2_1 + w^2_2 + w^2_3} = 1. \n",
    "\\end{equation}\n",
    "\n",
    "In addition, we set $b \\leq 0$ to have an unique equation for the decision boundary.\n",
    "\n",
    "(1) Compute the parameters $w_1$, $w_2$, $w_3$ and $b$ for the decision boundary that passes through three points $A = (3,2,4)$, $B = (-1,0,2)$, $C=(4,1,5)$ in the figure below.\n",
    "\n",
    "**Hint**: Please use the intercepts in the figure below to find the relation between $w_1, w_2, w_3$ and $b$. Then, substitute it into the normalization constraint to solve for parameters.\n",
    "\n",
    "(2) Use parameters from the above question to compute predictions for the following two data points: $D = (0,0,0)$, $E = (1,0,5)$.\n",
    "\n",
    "\n",
    "![Img4](imgs/4.png)\n",
    "\n",
    "_Points:_ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b3f27",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25a6bc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2.4\n",
    "In this problem, we attempt to obtain the optimal parameters $\\mathbf{w}^*$ and $b^*$ by using a standard gradient descent algorithm. Assume $p_i = p(y_i|x_i)$, solve for the gradient for $\\mathbf w$ and the gradient for b.\n",
    "\n",
    "We are given a classifier that performs classification in $\\mathbb{R}^2$ (the space of data points with 2 features $(x_1,x_2)$) with the following decision rule:\n",
    "\n",
    "\\begin{equation}\n",
    "h(x_1,x_2) = \\left\\{\n",
    "             \\begin{array}{ll}\n",
    "             +1,  & \\text{if }  x_1^2 + x_2^2 - 9 \\ge 0\\\\\n",
    "             -1,  & \\text{otherwise} . \n",
    "             \\end{array}  \n",
    "        \\right. \\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Draw the decision boundary of the classifier and shade the region where the classifier predicts +1. Make sure you have marked the $x_1$ and $x_2$ axes and the intercepts on those axes.\n",
    "\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe43e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x0 = ...\n",
    "y0 = ...\n",
    "r = ...\n",
    "\n",
    "circle = plt.Circle(( x0 , y0 ), r, fill=False) # (x0, y0) is the center of the circle and r is the radius\n",
    "\n",
    "# plot the boundary\n",
    "# plt.plot(boundary_x1s, boundary_x2s)\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.annotate('x1', [-4, 4], weight='bold')\n",
    "plt.annotate('x2', [-4, 4], weight='bold')\n",
    "\n",
    "# generate some random data points\n",
    "np.random.seed(0)\n",
    "N_samples = 60\n",
    "sample_x1s = np.random.rand(N_samples) * 8 - 4\n",
    "sample_x2s = np.random.rand(N_samples) * 8 - 4\n",
    "\n",
    "# predict the labels (1 or -1) of the samples, here the signed_distance is given by the equation x_1^2 + x_2^2 - 9\n",
    "# STEP 2\n",
    "signed_distance = ...\n",
    "# STEP 3\n",
    "positive = signed_distance >= 0\n",
    "negative = signed_distance < 0\n",
    "\n",
    "# plot the samples\n",
    "plt.scatter(sample_x1s[positive], sample_x2s[positive], color=\"g\", marker=\"+\", label='positive')\n",
    "plt.scatter(sample_x1s[negative], sample_x2s[negative], color=\"r\", marker=\"_\", label='negative')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.add_artist(circle)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.set_xticks( [-4, -2, 0, 2, 4])\n",
    "ax.set_yticks( [-3, -2, -1, 1, 2, 3])\n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3a2ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Question 3\n",
    "\n",
    "## 3.1 Function Defined by Scalars\n",
    "\n",
    "(1) Given a function $f(w) = (y_1-wx_1)^2$ where $(x_1,y_1) = (1,1)$ represents a data point, derive $\\displaystyle\\frac{\\partial f(w)}{\\partial w}$. \n",
    "\n",
    "(2) Given a function $f(w) = \\sum_{i\\in\\{1,2\\}} (y_i-wx_i)^2$ where $(x_1,y_1) = (1,1), (x_2,y_2)=(2,3)$ are two data points, derive $\\displaystyle\\frac{\\partial f(w)}{\\partial w}$. \n",
    "\n",
    "_Points:_ 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0252fae",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a3d95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3.2 Function Defined by Vectors\n",
    "\n",
    "Given a function $f(w) = (\\mathbf{y}-w\\mathbf{x})^T (\\mathbf{y}-w\\mathbf{x})$ where $\\mathbf{x}=[1,2]^T$ and $\\mathbf{y}=[1,3]^T$, derive $\\displaystyle\\frac{\\partial f(w)}{\\partial w}$. \n",
    "\n",
    "**Note**: In $f(w)$, $w \\in \\mathbb{R}$ is still a scalar.\n",
    "\n",
    "_Points:_ 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8c7d6",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5f223",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Question 4\n",
    "\n",
    "In this question, we still use the Iris dataset from Homework 1 Question 6. In fact, you can see the shape of array $X$ is $(150, 4)$ by running *X.shape*, which means it contains 150 data points where each has 4 features. Here, we will perform some basic data manipulation and calculate some statistics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56070e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load Iris Dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f50a71",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(1) Divide array $X$ evenly to five subsets of data points: \n",
    "\n",
    " Group 1: 1st to 30th data point,\n",
    "\n",
    " Group 2: 31st to 60th data point,\n",
    "\n",
    " Group 3: 61st to 90th data point,\n",
    "\n",
    " Group 4: 91st to 120th data point,\n",
    "\n",
    " Group 5: 121st to 150th data point.\n",
    "\n",
    "Then calculate the mean of feature vectors in each group. Your results should be five 4-dimensional vectors (i.e. shape of \n",
    "NumPy array can be $(4,1)$, $(1,4)$ or $(4,)$.  \n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62424d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q4_1(array):\n",
    "    ...\n",
    "    return mean_group1, mean_group2, mean_group3, mean_group4, mean_group5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da5de8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4.2\n",
    "Remove 2nd and 3rd features from array $X$, resulting a $150\\times2$ matrix. Then calculate the mean of all feature vectors. Your result should be a 2-dimensional vector.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3eac94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q4_2(array):\n",
    "    ...\n",
    "    return mean_del"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a78d8a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4.3\n",
    "Remove last 10 data points from array $X$, resulting a $140\\times4$ matrix. Then calculate the mean of feature vectors. Your result should be a 4-dimensional vector.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fe7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q4_3(array):\n",
    "    ...\n",
    "    return mean_del"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec3731",
   "metadata": {},
   "source": [
    "# End of A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2860df",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Please make sure to see the output of the gradescope autograder. You are responsible for waiting and ensuring that the autograder is executing normally for your submission. Please create a Piazza post if you see errors in autograder execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05463356",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True, files=['imgs', 'requirements.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbebd9",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "cogs118a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "otter": {
   "OK_FORMAT": false,
   "tests": {
    "A1_1": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"A1_1\"\npoints = 2\n\n@test_case(points=0, hidden=False)\n# sanity check\ndef q1_1_sanity_check(q1_1):\n    all_options = [\"A\", \"B\", \"C\", \"D\"]\n    check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n    assert check_valid(q1_1, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
    "A1_2": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"A1_2\"\npoints = 2\n\n@test_case(points=0, hidden=False)\n# sanity check\ndef q1_2_sanity_check(q1_2):\n    all_options = [\"A\", \"B\", \"C\", \"D\"]\n    check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n    assert check_valid(q1_2, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
    "A1_3a": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"A1_3a\"\npoints = 2\n\n@test_case(points=0, hidden=False)\n# sanity check\ndef q1_3a_sanity_check(q1_3a):\n    all_options = [\"A\", \"B\", \"C\", \"D\"]\n    check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n    assert check_valid(q1_3a, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
    "A1_3b": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"A1_3b\"\npoints = 2\n\n@test_case(points=0, hidden=False)\n# sanity check\ndef q1_3b_sanity_check(q1_3b):\n    all_options = [\"A\", \"B\", \"C\", \"D\"]\n    check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n    assert check_valid(q1_3b, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
    "A1_4": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"A1_4\"\npoints = 2\n\n@test_case(points=0, hidden=False)\n# sanity check\ndef q1_4_sanity_check(q1_4):\n    all_options = [\"A\", \"B\", \"C\", \"D\"]\n    check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n    assert check_valid(q1_4, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
    "A4_1": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"A4_1\"\npoints = 5\n\n",
    "A4_2": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"A4_2\"\npoints = 3\n\n",
    "A4_3": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"A4_3\"\npoints = 3\n\n"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
